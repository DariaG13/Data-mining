---
title: "Sprawozdanie z listy 4"
subtitle: "Eksploracja danych"
author: "Daria Grzelak, 277533"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage[OT4]{polski}
   - \usepackage[utf8]{inputenc}
   - \usepackage{graphicx}
   - \usepackage{float}
output: 
  pdf_document:
    toc: true
    fig_caption: yes
    fig_width: 5 
    fig_height: 4 
    number_sections: true
fontsize: 12pt 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache=TRUE) 
knitr::opts_chunk$set(fig.pos = "H", out.extra = "", fig.align = "center")
```

# Opis danych
W niniejszym raporcie będę dokonywać dalszej analizy danych, którymi są dane ``Glass`` z pakietu ``mlbench`` (te same, co w poprzednim). Wczytam te dane poniżej, razem z potrzebnymi pakietami.

```{r pakiety_i_wczytanie_danych}
# Pakiety
library(mlbench) # dane Glass
library(ipred) # potrzebne funkcje
library(randomForest) # las losowy
library(e1071)
library(MASS)
library(cluster)
library(factoextra)

# Wczytanie danych
data(Glass)

# Ustawienie ziarna generatora dla powtarzalności wyników
set.seed(123)
```

Dla przypomnienia, dane te mają `r dim(Glass)[1]` obserwacji oraz `r dim(Glass)[2]` zmiennych.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Nazwa}& \textbf{Typ} & \textbf{Opis}\\
\hline
RI & Liczbowa & Współczynnik załamania \\
\hline
Na & Liczbowa & Zawartość procentowa sodu \\
\hline
Mg & Liczbowa & Zawartość procentowa magnezu \\
\hline
Al & Liczbowa & Zawartość procentowa glinu \\
\hline
Si & Liczbowa & Zawartość procentowa krzemu \\
\hline
K & Liczbowa & Zawartość procentowa potasu \\
\hline
Ca & Liczbowa & Zawartość procentowa wapnia \\
\hline
Ba & Liczbowa & Zawartość procentowa baru \\
\hline
Fe & Liczbowa &  Zawartość procentowa żelaza \\
\hline
Type & Jakościowa & Typ szkła \\
\hline
\end{tabular}
\caption{Opis cech zawartych w danych Glass}
\label{opis_cech_2}
\end{table}

Tabela&nbsp;\ref{opis_cech_2} zawiera opis zmiennych.

# Zaawansowane metody klasyfikacji
W pierwszej części niniejszego sprawozdania przedstawię wybrane zaawansowane metody klasyfikacji.

## Ensemble learning
Na początku zastosuję metody operujące na rodzinach klasyfikatorów. Porównam algorytmy bagging i random forest.

\subsubsection{Bagging}
Pierwszy z testowanych algorytmów to algorytm bagging, polegający na wykonaniu określonej liczby bootstrapowych replikacji zbioru uczącego, skonstruowaniu dla każdej z nich klasyfikatora i wyznaczenia klasyfikatora ostatecznego, stosując zasadę głosowania większości.

```{r bagging, echo=FALSE, fig.cap="\\label{fig:baggingp}Wpływ liczby replikacji na dokładność klasyfikacji bagging"}
## Porównanie błedów dla różnych liczb replikacji
B.vector <- c(1, 5, 10, 20, 30, 40, 50, 100)
bagging.error.rates <- sapply(B.vector, function(b)  {errorest(Type~., data=Glass, model=bagging, nbagg=b, estimator="632plus", est.para=control.errorest(nboot = 20))$error})
plot(B.vector, bagging.error.rates, xlab="Liczba replikacji", ylab="Błąd klasyfikacji", main="Bagging: błędy dla różnych liczb replikacji", type="b")
grid()
```
Najmniejszy błąd klasyfikacji wynosi `r min(bagging.error.rates)` dla liczby replikacji równej `r B.vector[which.min(bagging.error.rates)]`.

\subsubsection{Random Forest}
Drugi z algorytmów, który przetestuję, to random forest – las losowy. Polega on na budowaniu nieskorelowanych drzew w oparciu o losowe podzbiory cech, a później wynik jest uśredniany. Porównam wyniki dla wybranych liczb drzew oraz liczb cech.

```{r random_forest1, echo=FALSE, fig.cap="\\label{fig:random_forest1p}Porównanie dokładności dla liczby drzew"}
#Wektor dla liczby drzew
rf.ntree.numbers <- c(1, seq(from = 5, to = 100, by=5))

# Algorytm
rf.ntree.error.rates <- sapply(rf.ntree.numbers, function(n)  {errorest(Type~., data=Glass, model=randomForest, ntree=n, estimator="632plus", est.para=control.errorest(nboot = 20))$error})

# Wykres
plot(rf.ntree.numbers, rf.ntree.error.rates, xlab="Liczba drzew", ylab="Błąd klasyfikacji", main="Random Forest: błędy dla różnej liczby drzew", type="b")
grid()
```

```{r random_forest2, echo=FALSE, fig.cap="\\label{fig:random_forest2p}Porównanie dokładności dla liczby cech"}
#Wektor dla liczby cech
rf.mtry.numbers <- 1:(ncol(Glass)-1)

# Algorytm
rf.mtry.error.rates <- sapply(rf.mtry.numbers, function(n)  {errorest(Type~., data=Glass, model=randomForest, mtry=n,  estimator="632plus", est.para=control.errorest(nboot = 20))$error})

#Wykres
plot(rf.mtry.numbers, rf.mtry.error.rates, xlab="Liczba cech", ylab="Błąd klasyfikacji", main="Random Forest: Błędy dla różnej liczby cech", type="b")
grid()
```

Najmniejsze błędy otrzymuję kolejno dla `r rf.ntree.numbers[which.min(rf.ntree.error.rates)]` drzew (`r min(rf.ntree.error.rates)`) i dla `r rf.mtry.numbers[which.min(rf.mtry.error.rates)]` parametrów (`r min(rf.mtry.error.rates)`). Mniejszy z tych błędów wynosi `r min(c(rf.ntree.error.rates, rf.mtry.error.rates))`.

\subsubsection{Różnice dla enseble learning}
Wykres&nbsp;\ref{fig:baggingp} pokazuje, że liczba replikacji ma wpływ na poziom błędu, lecz nie daje ogromnej różnicy, która jest na poziomie około 0,05. Na wykresach&nbsp;\ref{fig:random_forest1p} i&nbsp;\ref{fig:random_forest2p} można zaobserwować, że wybór odpowiedniej liczby drzew ma dużo większe znaczenie (wahania na poziomie ponad 0,1) niż cech. Jednocześnie lasy losowe dały lepsze wyniki niż bagging.

Porównując zaawansowane schematy klasyfikacji ze zwykłym drzewem (sprawozdani z listy 3), można zauważyć znaczną poprawę jakości klasyfikacji względem zwykłych drzew (dla zwykłych drzew najmniejszy błąd, jaki udało się osiągnąć, to 0.270182, więc najmniejszy błąd dla metod ensemble learning różni się od tego o `r 0.270182-min(c(rf.ntree.error.rates, rf.mtry.error.rates))`).

## Metoda wektorów nośnych
W drugiej kolejności testować będę metodę wektorów nośnych (SVM) dla jąder liniowego, radialnego i wielomianowego. Przed zastosowaniem metody przygotuję odpowiednie dane i funkcję pomocniczą.

```{r svm_przygotowanie_danych}
# Podział na zbiory uczący i testowy
rozmiar <- nrow(Glass)
learn.ind    <- sample(1:rozmiar, 2/3*rozmiar)
glass.learn <- Glass[learn.ind,]
glass.test <- Glass[-learn.ind,]
real.labels <- glass.test$Type
rozmiar.test <- length(real.labels)

# funkcja na przewidywanie dla różnych jąder i wartości kosztu
svm_create_and_predict <- function(k, C) {
  model <- svm(Type~., data=glass.learn, kernel=k, cost=C)
  pred.svm <- predict(model, newdata=glass.test)
  acc.svm   <- sum(diag(table(pred.svm, real.labels)))/rozmiar.test
  error.svm <- 1 - acc.svm
  return (error.svm)
}

# wektor kosztów do testu
koszty <- c(seq(from=0.1, to=0.9, by=0.1), 1:10,
            seq(from=20, to=100, by=10))

```

\subsubsection{Testy dla różnych jąder i wartości kosztu}

```{r svm_wykresy, echo=FALSE, fig.cap="\\label{fig:svm_wykresy_p}Wykresy błędów dla metody SVM przy zastosowaniu różnych jąder i z różnymi wartościami kosztu"}
# testy dla różnych jąder
svm.linear <- sapply(koszty, function(n) {svm_create_and_predict("linear", n)})
svm.polynomial <- sapply(koszty, function(n) {svm_create_and_predict("polynomial", n)})
svm.radial <- sapply(koszty, function(n) {svm_create_and_predict("radial", n)})

#Wykresy
plot(koszty, svm.radial, type="b", pch=16, col="green", ylab="error", main="Error ze wzgledu na jądro i koszt")
lines(koszty, svm.linear, type="b", pch=16, col="red")
lines(koszty, svm.polynomial, type="b", pch=16, col="blue")
legend("topright",legend=c("radial","linear", "polynomial"),col=c("green","red", "blue"), lwd=3, bg="azure2")
grid()
```
Na wykresie&nbsp;\ref{fig:svm_wykresy_p} łatwo można zauważyć, że najlepszy wynik ostatecznie został osiągnięty dla jądra radialnego (wyniósł `r min(svm.radial)` dla kosztu `r koszty[which.min(svm.radial)]`), ale jednocześnie ta metoda wynegerowała też największy ze wszystkich błędów. Jądro liniowe natomiast wykazuje najmniejsze zróżnicowanie błędów.

\subsubsection{Dostraranie kosztu i gammy dla jądra radialnego}
W następnej kolejności spróbuję dostroić koszt i gammę dla jądra radialnego i zobaczę, czy przyniesie to poprawę wyników.

```{r svm_tuning}
# SVM – jądro radialne z domyślnymi parametrami
model.def <- svm(Type~., data=glass.learn, kernel="radial")
pred.svm.def <- predict(model.def, newdata=glass.test)
acc.svm.def <- sum(diag(table(pred.svm.def, real.labels)))/rozmiar.test
error.svm.def <- 1 - acc.svm.def

# Optymalizacja parametrów C i gamma
C.range <- 2^((-4):4)
gamma.range <- 2^((-10):4)

radial.tune <- tune(svm, train.x=glass.learn[,1:9],
                    train.y=glass.learn[,10],
                    kernel="radial",
                    ranges=list(cost=C.range, gamma=gamma.range))

# Przypisanie najlepszych parametrów
C.best <- radial.tune$best.parameters[["cost"]]
gamma.best <- radial.tune$best.parameters[["gamma"]]

# SVM – jądro radialne ze zoptymalizowanymi parametrami
model.opt <- svm(Type~., data=glass.learn, kernel="radial", cost=C.best,
                 gamma=gamma.best)
pred.svm.opt <- predict(model.opt, newdata=glass.test)
acc.svm.opt   <- sum(diag(table(pred.svm.opt, real.labels)))/rozmiar.test
error.svm.opt <- 1 - acc.svm.opt

# techniczne do automatycznego uzupełnienia, które parametry lepsze
errors.comp <- c(error.svm.def, error.svm.opt)
parametry.comp <- c("domyślne", "zoptymalizowane")
```

Ostatecznie błędy wyniosły:

* `r error.svm.def` dla parametrów domyślnych,
* `r error.svm.opt` dla parametrów zoptymalizowanych.

Mniejszy jest błąd `r min(errors.comp)`, więc lepsze okazały się parametry `r parametry.comp[which.min(errors.comp)]`. Zauważyć można jednak, że błąd ten jest dość spory, podobny do zwykłych, niezaawansowanych metod klasyfikacji.

## Porównanie skuteczności metod
Porównując metody ensemble learning i SVM, skuteczniejsze okazały się te pierwsze, z lekką przewagą lasów losowych.

# Analiza skupień
Drugą część niniejszego raportu stanowi analiza skupień. Będę ją wykonywać dla danych Glass, jak wcześniej.

## Przygotowanie danych
Najpierw dokonam wstępnego przygotowania danych. Sprawdzę, czy dane mogą wymagać standaryzacji.

```{r glass_boxplot, echo=FALSE, fig.cap="\\label{fig:glass_boxplot_p}Wykresy pudełkowe dla zmiennych z danych Glass"}
boxplot(Glass[,1:9], las=2, col=rainbow(9), main="Wykresy zmiennych liczbowych")
```
Na wykresie&nbsp;\ref{fig:glass_boxplot_p} łatwo można zauważyć, że dane znacząco się różnią (choćby krzem ma wyższe wartości, co, oczywiście, wynika z tego, że szkło na ogół składa się przede wszystkim z niego), jednak zdecyduję się nie stosować standaryzacji. W dalszych krokach wyznaczę także macierz odmienności i przy pomocy metody PCA zredukuję wymiar, co przyda się do późniejszego rysowania wykresów.

```{r prepare_data}
#dane bez etykiet
#glass.wybrane <- as.data.frame(scale(Glass[,1:9]))
glass.wybrane <- as.data.frame(Glass[,1:9])

# macierz odmienności
glass.dis.mat <- daisy(glass.wybrane)
glass.dis.mat <- as.matrix(glass.dis.mat)

# PCA
glass.pca <- prcomp(glass.wybrane, retx=TRUE)
```

## Metoda grupująca (PAM)
Jako pierwszą z metod wykorzystam metodę grupującą – PAM. Najpierw przedstawię ogólny zarys dla sześciu skupień, czyli tylu, ile rzeczywiście jest klas.

```{r pam, echo=FALSE, fig.cap="\\label{fig:pam_p}Wykres rozrzutu dla sześciu skupień (PAM)"}
glass.pam <- pam(x=glass.dis.mat, diss=TRUE, k=6)
etykietki.pam <- glass.pam$clustering
# wykres rozrzutu
plot(glass.pca$x[,1],glass.pca$x[,2],col=as.numeric(Glass$Type),pch=etykietki.pam, main="Wykres rozrzutu dla sześciu skupień")
legend("topleft", title="Klasa  Przypisanie",
       legend=c("1", "2", "3", "5", "6", "7", "1", "2", "3", "5", "6", "7"), 
       col=c(1,2,3,4,5,6,rep("black", 6)), pch=c(rep(1,6), 1,2,3,4,5,6),ncol=2, bg="azure2")
grid()
```
Obserwując skupiska na wykresie&nbsp;\ref{fig:pam_p}, można zauważyć brak jakiejś większej zgodności pomiędzy skupiskami i przypisaniami a rzeczywistymi klasami. Dwa największe skupiska są dość zwarte i spójne, ale jest słaba separacja – wiele klas się na siebie nakłada.

```{r pam_informacje}
#Średnia wartość Silhouette
print(paste("Średnia wartość silhouette:",glass.pam$silinfo$avg.width))
print("Macierz pomyłek:")
print(table(etykietki.pam,Glass$Type))

#MatchClasses
matchClasses(table(etykietki.pam,Glass$Type))
```

\subsubsection{Różna liczba skupień}
W następnym kroku spróbuję odnaleźć optymalną liczbę skupień.

```{r pam_rozne_skupienia}
# Liczby skupień od 1 do 6
clusters <- 1:6

# Funkcja pomocnicza
pam_diff_c <- function(c) {
  # PAM dla odpowiedniej liczby skupień
  glass.pam.k <- pam(x=glass.dis.mat, diss=TRUE, k=c)
  etykietki.pam.k <- glass.pam.k$clustering
  
  # macierz pomyłek i silhouette
  sil <- glass.pam.k$silinfo$avg.width
  tabela <- table(etykietki.pam.k,Glass$Type)

  # Wydrukuj informacje
  print(paste(c, "clusters:"))
  print(paste("Średni wskaźnik silhouette:", sil))
  print("Macierz pomyłek i wskaźnik dopasowania:")
  print(tabela)
  matchClasses(tabela)
}

# Zastosowanie funkcji
sapply(clusters, function(c) {pam_diff_c(c)})
```
Wyniki wskazują, że wraz z liczbą skupień wzrasta dokładność według funkcji matchClasses. Wskaźnik silhouette jest za to najwyższy dla 2 skupień, choć w żadnym przypadku nie przekracza nawet wartości 0,5, więc według niego obiekty nie są zbyt dobrze przypisywane. Uwaga: dla 1 skupienia wskaźnik silhouette nie jest wyznaczany.

Będę kierować się wskaźnikiem zewnętrznym i uznam za optymalną liczbę skupień 6 skupień.

## Metoda hierarchiczna (AGNES)
Drugą metodą analizy skupień, którą przeanalizuję, jest metoda hierarchiczna – AGNES. Przetestuję różne metody łączenia skupień i znajdę najlepszą z nich, wraz z optymalną liczbą skupień.

```{r agnes_intro}
# Różne metody łączenia skupień
glass.agnes.avg <- agnes(x=glass.dis.mat,diss=TRUE, method="average")
glass.agnes.single <- agnes(x=glass.dis.mat,diss=TRUE, method="single")
glass.agnes.complete <- agnes(x=glass.dis.mat,diss=TRUE, method="complete")
```

```{r dendrogram1, echo=FALSE, fig.cap="\\label{fig:dendrogram1_p}Dendrogram dla metody average"}
par(cex=0.5)
plot(glass.agnes.avg,which.plots=2,main="AGNES: average linkage")
```

```{r dendrogram2, echo=FALSE, fig.cap="\\label{fig:dendrogram2_p}Dendrogram dla metody single"}
par(cex=0.5)
plot(glass.agnes.single,which.plots=2,main="AGNES: single linkage")
```

```{r dendrogram3, echo=FALSE, fig.cap="\\label{fig:dendrogram3_p}Dendrogram dla metody complete"}
par(cex=0.5)
plot(glass.agnes.complete,which.plots=2, main="AGNES: complete linkage")
```

W przypadku single linkage bardzo dużo elementów łączy się na dole drzewa, dla dwóch pozostałych metod jest więcej połączeń na różnych poziomach.

W następnych krokach będę analizować każdą metodę pod kątem optymalnej liczby skupień.

```{r agnes_clusters}
# Utworzenie wektorów dla każdej metody i liczby skupień
glass.avg.clusters <- sapply(clusters, function(c)
  {cutree(glass.agnes.avg, k=c)})
glass.single.clusters <- sapply(clusters, function(c)
  {cutree(glass.agnes.single, k=c)})
glass.complete.clusters <- sapply(clusters, function(c)
  {cutree(glass.agnes.complete, k=c)})
```

Na wykresach przedstawię wyniki dla sześciu skupień, czyli tylu, ile klas jest naprawdę.

```{r agnes_avg, echo=FALSE, fig.cap="\\label{fig:agnes_avg_p}Wykres rozrzutu dla sześciu skupień (AGNES avg)"}
# wykres rozrzutu
plot(glass.pca$x[,1],glass.pca$x[,2],col=as.numeric(Glass$Type),pch=glass.avg.clusters[,6], main="AGNES avg – sześć skupień")
legend("topleft", title="Klasa  Przypisanie",
       legend=c("1", "2", "3", "5", "6", "7", "1", "2", "3", "5", "6", "7"), 
       col=c(1,2,3,4,5,6,rep("black", 6)), pch=c(rep(1,6), 1,2,3,4,5,6),ncol=2, bg="azure2")
grid()
```
```{r agnes_single, echo=FALSE, fig.cap="\\label{fig:agnes_single_p}Wykres rozrzutu dla sześciu skupień (AGNES single)"}
# wykres rozrzutu
plot(glass.pca$x[,1],glass.pca$x[,2],col=as.numeric(Glass$Type),pch=glass.single.clusters[,6], main="AGNES single – sześć skupień")
legend("topleft", title="Klasa  Przypisanie",
       legend=c("1", "2", "3", "5", "6", "7", "1", "2", "3", "5", "6", "7"), 
       col=c(1,2,3,4,5,6,rep("black", 6)), pch=c(rep(1,6), 1,2,3,4,5,6),ncol=2, bg="azure2")
grid()
```

```{r agnes_complete, echo=FALSE, fig.cap="\\label{fig:agnes_complete_p}Wykres rozrzutu dla sześciu skupień (AGNES complete)"}
# wykres rozrzutu
plot(glass.pca$x[,1],glass.pca$x[,2],col=as.numeric(Glass$Type),pch=glass.complete.clusters[,6], main="AGNES complete – sześć skupień")
legend("topleft", title="Klasa  Przypisanie",
       legend=c("1", "2", "3", "5", "6", "7", "1", "2", "3", "5", "6", "7"), 
       col=c(1,2,3,4,5,6,rep("black", 6)), pch=c(rep(1,6), 1,2,3,4,5,6),ncol=2, bg="azure2")
grid()
```
Dla metod avg i single przypisania niezbyt mają sens, gdyż w obu największych skupiskach dominuje jedno przypisanie. Inaczej jest w przypadku metody complete – wykres&nbsp;\ref{fig:agnes_complete_p} pokazuje podział dwóch największych skupisk na dwie różne klasy. Ponadto skupisko związane z klasą 7 jest poprawnie przypisane. Za to w przypadku skupiska, gdzie zostaje przypisana klasa 1, w rzeczywistości przedstawiciele tej klasy się tam plasują, jednak pojawia się trochę przedstawicieli klas 2 i 3.

\subsubsection{Optymalna liczba skupień}
Tak jak wcześniej, wyznaczę wskaźniki silhouette i matchClasses, aby wybrać optymalne liczby skupień.

**Avg:**

```{r agnes_avg_wskazniki}
for (n in 1:6) {
  print(paste(n,"clusters:"))
  sil.agnes.avg <- silhouette(x=glass.avg.clusters[,n], dist=glass.dis.mat)
  print(summary(sil.agnes.avg))
  tabela <- table(glass.avg.clusters[,n],Glass$Type)
  print(tabela)
  matchClasses(tabela)
}
```

**Single:**

```{r agnes_single_wskazniki}
for (n in 1:6) {
  print(paste(n,"clusters:"))
  sil.agnes.single <- silhouette(x=glass.single.clusters[,n], 
                                 dist=glass.dis.mat)
  print(summary(sil.agnes.single))
  tabela <- table(glass.single.clusters[,n],Glass$Type)
  print(tabela)
  matchClasses(tabela)
}
```

**Complete:**

```{r agnes_complete_wskazniki}
for (n in 1:6) {
  print(paste(n,"clusters:"))
  sil.agnes.complete <- silhouette(x=glass.complete.clusters[,n], 
                                 dist=glass.dis.mat)
  print(summary(sil.agnes.complete))
  tabela <- table(glass.complete.clusters[,n],Glass$Type)
  print(tabela)
  matchClasses(tabela)
}
```
W związku z powyższym można zauważyć następujące rzeczy:

* najwyższy średni silhouette dla avg – 0,63428 przy 2 klastrach,
* najwyższy wskaźnik zewnętrzny dla avg – 38,32% przy 6 klastrach,
* najwyższy średni silhouette dla single – 37,38%  przy 6 klastrach,
* najwyższy wskaźnik zewnętrzny dla single – 0,63428 przy 2 klastrach,
* najwyższy średni silhouette dla complete – 0,571 przy 2 klastrach,
* najwyższy wskaźnik zewnętrzny dla complete – 50% przy 6 klastrach.

Zatem najbardziej obiecujące jest użycie metody łączenia complete dla 6 klastrów, czyli tylu, ile jest klas.

## Charakterystyki skupień
W obu przypadkach najoptymalniejsze okazało się wykorzystanie 6 skupień, tak więc dla nich będę robić. Wykresy dla tej liczby zostały przedstawione wcześniej, zatem przejdę jedynie do analizy samych skupień.

\subsubsection{PAM}
Najpierw porównam cechy dla obiektów należących do poszczególnych skupień i zrobię to na podstawie wykresów pudełkowych. Najpierw jednak dokleję do danych glass przypisane etykietki, by było łatwiej.

```{r zbior_z_przypisaniami}
#Utworzenie odpowiedniego zbioru
glass.z.przypisaniami <- as.data.frame(cbind(glass.wybrane, 
                                             glass.pam$clustering))
names(glass.z.przypisaniami)[10] <- "cluster"
```

Poniżej natomiast przedstawię wykresy dla wszystkich cech.

```{r boxplot_RI, echo=FALSE, fig.cap="\\label{boxplot_RI_p}Wykresy pudełkowe dla różnych klastrów, dla cechy RI"}
boxplot(RI~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs RI")
```

```{r boxplot_Na, echo=FALSE, fig.cap="\\label{boxplot_Na_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Na"}
boxplot(Na~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Na")
```

```{r boxplot_Mg, echo=FALSE, fig.cap="\\label{boxplot_Mg_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Mg"}
boxplot(Mg~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Mg")
```

```{r boxplot_Al, echo=FALSE, fig.cap="\\label{boxplot_Al_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Al"}
boxplot(Al~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Al")
```

```{r boxplot_Si, echo=FALSE, fig.cap="\\label{boxplot_Si_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Si"}
boxplot(Si~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Si")
```

```{r boxplot_K, echo=FALSE, fig.cap="\\label{boxplot_K_p}Wykresy pudełkowe dla różnych klastrów, dla cechy K"}
boxplot(K~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs K")
```

```{r boxplot_Ca, echo=FALSE, fig.cap="\\label{boxplot_Ca_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Ca"}
boxplot(Ca~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Ca")
```

```{r boxplot_Ba, echo=FALSE, fig.cap="\\label{boxplot_Ba_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Ba"}
boxplot(Ba~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Ba")
```

```{r boxplot_Fe, echo=FALSE, fig.cap="\\label{boxplot_RI_p}Wykresy pudełkowe dla różnych klastrów, dla cechy Fe"}
boxplot(Fe~cluster, data=glass.z.przypisaniami, col=rainbow(6), main="Cluster vs Fe")
```
Cechy są bardziej zróżnicowane względem klastrów niż względem rzeczywistych klas (patrz: sprawozdanie 3), a uwagę zwracają szczególnie cechy RI, Na i Si, zwłaszcza Si jest brdziej zróżnicowana niż przy oryginalnym podziale.

Sprawdzę także, które z obiektów są medoidami.

```{r medoidy}
# Wyświetlenie medoidów
Glass[glass.pam$medoids,]
```

W tym przypadku medoidy należą do klas 1, 3, 5 oraz 7, a więc nie wszystkie są uwzględnione w tym przypadku. Dla tych obiektów dość mocno zróżnicowana jest zawartość wapnia, a także potasu. Ponasto obiekt z klasy 7 jest jedynym, który ma niezerową zawartość baru.

\subsubsection{AGNES}
Teraz taką samą analizę cech wykonam dla metody AGNES. Wybiorę metodę complete, dla 6 skupień.

```{r zbior_z_przypisaniami2}
#Utworzenie odpowiedniego zbioru
glass.z.przypisaniami2 <- as.data.frame(cbind(glass.wybrane, 
                                             glass.complete.clusters[,6]))
names(glass.z.przypisaniami2)[10] <- "cluster"
```

```{r boxplot_RI2, echo=FALSE, fig.cap="\\label{boxplot_RI_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy RI"}
boxplot(RI~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs RI")
```

```{r boxplot_Na2, echo=FALSE, fig.cap="\\label{boxplot_Na_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Na"}
boxplot(Na~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Na")
```

```{r boxplot_Mg2, echo=FALSE, fig.cap="\\label{boxplot_Mg_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Mg"}
boxplot(Mg~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Mg")
```

```{r boxplot_Al2, echo=FALSE, fig.cap="\\label{boxplot_Al_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Al"}
boxplot(Al~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Al")
```

```{r boxplot_Si2, echo=FALSE, fig.cap="\\label{boxplot_Si_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Si"}
boxplot(Si~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Si")
```

```{r boxplot_K2, echo=FALSE, fig.cap="\\label{boxplot_K_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy K"}
boxplot(K~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs K")
```

```{r boxplot_Ca2, echo=FALSE, fig.cap="\\label{boxplot_Ca_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Ca"}
boxplot(Ca~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Ca")
```

```{r boxplot_Ba2, echo=FALSE, fig.cap="\\label{boxplot_Ba_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Ba"}
boxplot(Ba~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Ba")
```

```{r boxplot_Fe2, echo=FALSE, fig.cap="\\label{boxplot_RI_p2}Wykresy pudełkowe dla różnych klastrów, dla cechy Fe"}
boxplot(Fe~cluster, data=glass.z.przypisaniami2, col=rainbow(6), main="Cluster vs Fe")
```

Dla tej metody można zaobserwować nieco większe zróżnicowanie cech niż dla PAM. Najbardziej wyróżniają się RI, Si (podobnie jak w PAM), ale też Ca.

## Wnioski
Ze wszystkich tych metod najlepiej sprawdziła się metoda PAM, dająca niemal 60% poprawnych przypasowań dla 6 klastrów. Potwierdza to lekkie podobieństwo pomiędzy wykresami pudełkowymi dla klastrów i dla poszczególnych klas (sprawozdanie 3). Dla metody AGNES, choć udało się zgromadzić większe rozróżnienie w obrębie poszczególnych cech, to jednak poskutowało to gorszymi wynikami w przypisywaniu poprawnych klas.